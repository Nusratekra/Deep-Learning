{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP7/tE/gi0uUZLzX/eVXRbg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UF22f7url_KS","executionInfo":{"status":"ok","timestamp":1689004190495,"user_tz":-360,"elapsed":229638,"user":{"displayName":"Tanmoy Mazumder","userId":"07166002203080382723"}},"outputId":"85d68a06-d986-4832-fd67-d2f856712a55"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 26421880/26421880 [00:01<00:00, 15888834.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 29515/29515 [00:00<00:00, 270043.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4422102/4422102 [00:00<00:00, 5081596.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5148/5148 [00:00<00:00, 6371282.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["Training Progress: 100%|██████████| 10/10 [03:30<00:00, 21.06s/it, Epoch=10, Loss=0.0431]\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 90.41%\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchvision.utils import make_grid\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","\n","# Define the CNN model\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n","        self.relu = nn.ReLU()\n","        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n","        self.fc = nn.Linear(32 * 7 * 7, 10)  # Fashion MNIST has 10 classes ##\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","        x = self.conv2(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        return x\n","\n","# Set device (GPU if available, else CPU)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Hyperparameters\n","num_epochs = 10\n","batch_size = 64\n","learning_rate = 0.001\n","\n","# Load and preprocess the Fashion MNIST dataset\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))\n","])\n","\n","train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","# Initialize the model\n","model = CNN().to(device)\n","\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Display some images before training\n","# sample_images, sample_labels = iter(train_loader).next()\n","# sample_grid = make_grid(sample_images[:25], nrow=5, padding=2, normalize=True)\n","# plt.imshow(sample_grid.permute(1, 2, 0))\n","# plt.axis('off')\n","# plt.title('Fashion MNIST Sample Images')\n","# plt.show()\n","\n","# Training loop with progress bar\n","total_step = len(train_loader)\n","progress_bar = tqdm(range(num_epochs), desc=\"Training Progress\")\n","for epoch in progress_bar:\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Update progress bar\n","        # progress_bar.set_postfix({'Epoch': epoch+1, 'Loss': loss.item():.4f})\n","        progress_bar.set_postfix({'Epoch': epoch+1, 'Loss': f'{loss.item():.4f}'})\n","\n","\n","# Testing loop\n","model.eval()\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        # Forward pass\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    accuracy = 100 * correct / total\n","    print(f\"Test Accuracy: {accuracy:.2f}%\")"]},{"cell_type":"code","source":["torch.save(model.state_dict(), 'cnn_model.pth')"],"metadata":{"id":"aHqMl9nHojTu","executionInfo":{"status":"ok","timestamp":1689004316744,"user_tz":-360,"elapsed":380,"user":{"displayName":"Tanmoy Mazumder","userId":"07166002203080382723"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"i5HbezdLojpo"},"execution_count":null,"outputs":[]}]}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***Creating Neural Network***"
      ],
      "metadata": {
        "id": "0Te02oRDBClL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4rWPhCaY4ZQE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn # For nural netwok\n",
        "import torch.optim as optim #For optimization oparation\n",
        "from sklearn.datasets import fetch_california_housing #for take some data\n",
        "from sklearn.preprocessing import StandardScaler #for normalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset,DataLoader #Dataloder => every package to train\n",
        "from tqdm import tqdm #For progress bar"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inharit the data set and make my own dataset\n",
        "class HousingDataset(Dataset):\n",
        "  def __init__(self,data,targets):\n",
        "    self.data = data\n",
        "    self.targets = targets\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.targets)\n",
        "\n",
        "  def __getitem__(self, idx):# will take the id and show us the objects\n",
        "        x = torch.tensor(self.data[idx], dtype=torch.float32)\n",
        "        y = torch.tensor(self.targets[idx], dtype=torch.float32)\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "Sf_73pH2EepY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = fetch_california_housing()\n",
        "x = data['data']\n",
        "y = data['target']"
      ],
      "metadata": {
        "id": "L9cXkQaxF3uT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform data preprocessing\n",
        "scaler = StandardScaler()\n",
        "x = scaler.fit_transform(x)\n",
        "x_train,x_test,y_train,y_test =train_test_split(x,y,test_size=0.3,random_state= 42)\n",
        "\n",
        "train_dataset = HousingDataset(x_train,y_train)\n",
        "test_dataset = HousingDataset(x_test,y_test)\n",
        "train_dataloder = DataLoader(train_dataset,batch_size =64,shuffle = True)\n",
        "test_dataloder = DataLoader(test_dataset,batch_size= 64)"
      ],
      "metadata": {
        "id": "JOvC_A-aGck5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a neural network model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        # Initialize the parent class (nn.Module)\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "\n",
        "        # First fully connected (dense) layer\n",
        "        # input_size  -> number of features in input data\n",
        "        # 64          -> number of neurons in hidden layer\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "\n",
        "        # ReLU activation function (adds non-linearity)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Output layer\n",
        "        # 64 -> hidden neurons\n",
        "        # 1  -> single output value (for regression)\n",
        "        self.fc2 = nn.Linear(64, 1)\n",
        "\n",
        "    # Forward pass: defines how data flows through the network\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)   # Linear transformation\n",
        "        x = self.relu(x)  # Apply activation function\n",
        "        x = self.fc2(x)   # Final output layer\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "X2LuiNoLMmMR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "model = NeuralNetwork(input_size=x_train.shape[1])\n",
        "# Loss function (Mean Squared Error for regression)\n",
        "criterion = nn.MSELoss()\n",
        "# Optimizer (Adam)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "# Device configuration (GPU if available, else CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "# Convert training data to tensors\n",
        "x_train = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
        "x_test = torch.tensor(x_test, dtype=torch.float32).to(device)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32).to(device)\n"
      ],
      "metadata": {
        "id": "XU_xLvmcNlAO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a sample from the dataset\n",
        "print(\"Sample from the dataset:\")\n",
        "\n",
        "sample_idx = 0  # index of the sample to inspect\n",
        "sample_input, sample_target = train_dataset[sample_idx]\n",
        "\n",
        "print(\"Input:\", sample_input)     # feature vector\n",
        "print(\"Target:\", sample_target)   # corresponding label\n",
        "print()\n",
        "\n",
        "# Training configuration\n",
        "num_epochs = 10  # number of full passes over the training dataset\n",
        "# Training and evaluation loop\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # Training phase\n",
        "    model.train()            # set model to training mode\n",
        "    train_loss = 0.0         # accumulator for training loss\n",
        "\n",
        "    # Iterate over training batches\n",
        "    for inputs, targets in tqdm(train_dataloder):\n",
        "\n",
        "        # Move batch data to CPU/GPU\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # Forward pass: model prediction\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute loss (squeeze removes extra dimension: [B,1] -> [B])\n",
        "        loss = criterion(outputs.squeeze(), targets)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()  # clear previous gradients\n",
        "        loss.backward()        # compute gradients\n",
        "        optimizer.step()       # update model parameters\n",
        "\n",
        "        # Accumulate loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Average training loss for this epoch\n",
        "    train_loss /= len(train_dataloder)\n",
        "\n",
        "    #Evaluation phase\n",
        "    model.eval()              # set model to evaluation mode\n",
        "    test_loss = 0.0           # accumulator for test loss\n",
        "\n",
        "    # Disable gradient computation during evaluation\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in test_dataloder:\n",
        "\n",
        "            # Move test batch to CPU/GPU\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(outputs.squeeze(), targets)\n",
        "\n",
        "            # Accumulate test loss\n",
        "            test_loss += loss.item()\n",
        "\n",
        "    # Average test loss for this epoch\n",
        "    test_loss /= len(test_dataloder)\n",
        "    # Logging results\n",
        "    print(\n",
        "        f\"Epoch [{epoch + 1}/{num_epochs}] | \"\n",
        "        f\"Train Loss: {train_loss:.4f} | \"\n",
        "        f\"Test Loss: {test_loss:.4f}\"\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uMQvCVtOsgI",
        "outputId": "90ea69fd-b5ae-4afa-bcd9-a1c12e3a4946"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample from the dataset:\n",
            "Input: tensor([ 0.1371,  0.5054,  0.1832, -0.2557, -0.1832, -0.0082, -0.7968,  0.7735])\n",
            "Target: tensor(1.9380)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 226/226 [00:00<00:00, 413.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] | Train Loss: 0.3752 | Test Loss: 0.3729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 226/226 [00:00<00:00, 405.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10] | Train Loss: 0.3703 | Test Loss: 0.3684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 226/226 [00:00<00:00, 404.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10] | Train Loss: 0.3739 | Test Loss: 0.3720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 226/226 [00:00<00:00, 416.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10] | Train Loss: 0.3620 | Test Loss: 0.3652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 226/226 [00:00<00:00, 412.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10] | Train Loss: 0.3592 | Test Loss: 0.3639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 226/226 [00:00<00:00, 404.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10] | Train Loss: 0.3578 | Test Loss: 0.3565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 226/226 [00:00<00:00, 423.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10] | Train Loss: 0.3542 | Test Loss: 0.3526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 226/226 [00:00<00:00, 321.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10] | Train Loss: 0.3484 | Test Loss: 0.3507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 226/226 [00:00<00:00, 319.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10] | Train Loss: 0.3463 | Test Loss: 0.3490\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 226/226 [00:00<00:00, 330.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10] | Train Loss: 0.3440 | Test Loss: 0.3482\n"
          ]
        }
      ]
    }
  ]
}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPkODmdeW2ewdCPV5+HomS/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"1GgbYk2ueGzf","executionInfo":{"status":"ok","timestamp":1688904614181,"user_tz":-360,"elapsed":373,"user":{"displayName":"Tanmoy Mazumder","userId":"07166002203080382723"}}},"outputs":[],"source":["class Person:\n","    def __init__(self, name, age):\n","        self.name = name\n","        self.age = age\n","\n","class Student(Person):\n","    def __init__(self, name, age, id, semester, section):\n","        super().__init__(name, age)\n","        self.id = id\n","        self.semester = semester\n","        self.section = section\n","\n","    def study(self):\n","        print(\"studying\")\n"]},{"cell_type":"code","source":["students = [ Student(\"Abrar\", 20, 12142352, \"3-1\", \"B\"),\n","            Student(\"XYZ\", 22, 1242352, \"3-2\", \"A\")]"],"metadata":{"id":"GYOweFz7jDif","executionInfo":{"status":"ok","timestamp":1688904617541,"user_tz":-360,"elapsed":376,"user":{"displayName":"Tanmoy Mazumder","userId":"07166002203080382723"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["for i in students:\n","    print(f\"name:{i.name} \")\n","    i.study()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wTatAj4pj50R","executionInfo":{"status":"ok","timestamp":1688904705482,"user_tz":-360,"elapsed":584,"user":{"displayName":"Tanmoy Mazumder","userId":"07166002203080382723"}},"outputId":"13058d8a-7cc2-431a-9266-71219181cf32"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["name:Abrar \n","studying\n","name:XYZ \n","studying\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.datasets import fetch_california_housing\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","\n","class HousingDataset(Dataset):\n","    def __init__(self, data, targets):\n","        self.data = data\n","        self.targets = targets\n","\n","    def __len__(self):\n","        return len(self.targets)\n","\n","    def __getitem__(self, idx):\n","        x = torch.tensor(self.data[idx], dtype=torch.float32)\n","        y = torch.tensor(self.targets[idx], dtype=torch.float32)\n","        return x, y\n","\n","data = fetch_california_housing()\n","X = data['data']\n","y = data['target']\n","\n","# Perform data preprocessing\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","train_dataset = HousingDataset(X_train, y_train)\n","test_dataset = HousingDataset(X_test, y_test)\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64)\n","\n","class NeuralNetwork(nn.Module):\n","    def __init__(self, input_size):\n","        super(NeuralNetwork, self).__init__()\n","        self.fc1 = nn.Linear(input_size, 64)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(64, 1)\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        return x\n","\n","model = NeuralNetwork(input_size=X.shape[1])\n","\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","y_train = torch.tensor(y_train, dtype=torch.float32).to(device)\n","X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n","y_test = torch.tensor(y_test, dtype=torch.float32).to(device)\n","\n","# Display a sample of the dataset\n","print(\"Sample from the dataset:\")\n","sample_idx = 0\n","sample_input, sample_target = train_dataset[sample_idx]\n","print(\"Input:\", sample_input)\n","print(\"Target:\", sample_target)\n","print()\n","\n","num_epochs = 10\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_loss = 0.0\n","\n","    for inputs, targets in tqdm(train_loader):\n","        inputs = inputs.to(device)\n","        targets = targets.to(device)\n","\n","        # Forward pass\n","        outputs = model(inputs)\n","        loss = criterion(outputs.squeeze(), targets)\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","\n","    # Compute average training loss\n","    train_loss /= len(train_loader)\n","\n","    # Evaluate the model on the test set\n","    model.eval()\n","    test_loss = 0.0\n","    test_correct = 0\n","\n","    with torch.no_grad():\n","        for inputs, targets in test_loader:\n","            inputs = inputs.to(device)\n","            targets = targets.to(device)\n","\n","            # Forward pass\n","            outputs = model(inputs)\n","            loss = criterion(outputs.squeeze(), targets)\n","\n","            test_loss += loss.item()\n","\n","    # Compute average test loss\n","    test_loss /= len(test_loader)\n","\n","    # Compute test accuracy\n","    test_accuracy = 100.0 - test_loss\n","\n","    # Print training and testing statistics\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n","          f\"Train Loss: {train_loss:.4f}, \"\n","          f\"Test Accuracy: {test_accuracy:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kw1da-trkk8k","executionInfo":{"status":"ok","timestamp":1688908235704,"user_tz":-360,"elapsed":7933,"user":{"displayName":"Tanmoy Mazumder","userId":"07166002203080382723"}},"outputId":"1d08c301-f141-40e7-be7d-7066f6cda1cb"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample from the dataset:\n","Input: tensor([-0.3217,  0.3465, -0.1663, -0.1905,  0.7723,  0.0598, -1.3680,  1.2676])\n","Target: tensor(1.0300)\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 258/258 [00:00<00:00, 421.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 1.7177, Test Accuracy: 99.29%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 258/258 [00:00<00:00, 460.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [2/10], Train Loss: 0.6347, Test Accuracy: 99.46%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 258/258 [00:00<00:00, 432.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [3/10], Train Loss: 0.4888, Test Accuracy: 99.53%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 258/258 [00:00<00:00, 436.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [4/10], Train Loss: 0.4364, Test Accuracy: 99.57%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 258/258 [00:00<00:00, 309.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [5/10], Train Loss: 0.4114, Test Accuracy: 99.58%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 258/258 [00:00<00:00, 289.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [6/10], Train Loss: 0.3983, Test Accuracy: 99.60%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 258/258 [00:00<00:00, 298.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [7/10], Train Loss: 0.3887, Test Accuracy: 99.60%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 258/258 [00:00<00:00, 464.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [8/10], Train Loss: 0.3800, Test Accuracy: 99.61%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 258/258 [00:00<00:00, 454.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [9/10], Train Loss: 0.3733, Test Accuracy: 99.62%\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 258/258 [00:00<00:00, 448.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [10/10], Train Loss: 0.3676, Test Accuracy: 99.62%\n"]}]}]}